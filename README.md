#Custom Autograd Engine
##Overview
This project focuses on the design and implementation of a custom autograd engine, a fundamental tool in machine learning frameworks that automates the process of differentiation. The primary objective of this project is to build a dynamic, modular system capable of performing forward and backward propagation inspired by popular frameworks like PyTorch. The engine supports dynamic computational graph creation, allowing users to efficiently compute gradients for optimizing complex models.
The methodology involves the creation of a Tensor class to serve as the core data structure, encapsulating data, gradients, and operations within a computational graph. Each operation (e.g., addition, multiplication, matrix multiplication) is tracked in the graph, enabling automatic differentiation through a recursive backward pass. Modular components such as Linear layers, activation functions (e.g., ReLU, Sigmoid), and optimizers (e.g., Stochastic Gradient Descent) are developed to provide a comprehensive foundation for building neural networks. The frameworkâ€™s modularity ensures that components can be reused and extended for various tasks, making the engine adaptable and efficient. The key features of the engine include:
1. Dynamic Computational Graph: Automatically constructs a graph during forward propagation and efficiently traverses it during backward propagation.
2. Gradient Computation: Supports backpropagation through any chain of operations, ensuring the correct propagation of gradients.
3. Modular Design: Incorporates layers, activation functions, and optimizers as modular entities, enabling users to create and optimize custom models with ease.
4. Visualization Tools: Tracks and visualizes metrics such as training loss and gradient flow, aiding in debugging and performance evaluation.



##Comparison to Popular Frameworks Like PyTorch
This custom autograd engine, while inspired by frameworks like PyTorch, serves as a lightweight and educational alternative to these industrial-grade tools. PyTorch, TensorFlow, and JAX are robust, production-ready frameworks optimized for scalability, distributed computing, and hardware acceleration. In contrast, this custom implementation prioritizes simplicity, transparency, and educational value.
Key comparisons include:
1. Computational Graphs: PyTorch employs a dynamic computational graph that is constructed during the forward pass and reused during the backward pass. Similarly, the custom engine dynamically builds and traverses the graph but lacks optimizations like memory reuse and parallel computation present in PyTorch.
2. Gradient Computation: PyTorch handles complex operations with automatic differentiation for hundreds of predefined functions. The custom engine supports a smaller set of operations but focuses on clarity and the foundational principles of gradient computation.
3. Extensibility: While PyTorch allows the seamless addition of custom layers, activation functions, and loss functions, the custom implementation demonstrates this extensibility on a smaller scale. Users can add new layers or operations by defining their forward and backward propagation rules.
4. Performance: PyTorch leverages GPU acceleration and highly optimized C++ backends for efficient computation. The custom engine, written purely in Python and NumPy, is designed for educational use and is best suited for small-scale experiments.